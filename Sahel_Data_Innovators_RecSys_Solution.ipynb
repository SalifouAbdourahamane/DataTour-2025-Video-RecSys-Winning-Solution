{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1408bea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-16T01:19:10.383983Z",
     "iopub.status.busy": "2025-12-16T01:19:10.383758Z",
     "iopub.status.idle": "2025-12-16T04:36:57.619208Z",
     "shell.execute_reply": "2025-12-16T04:36:57.618397Z"
    },
    "papermill": {
     "duration": 11867.240871,
     "end_time": "2025-12-16T04:36:57.620448",
     "exception": false,
     "start_time": "2025-12-16T01:19:10.379577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ULTRA-ENHANCED PPM MODEL\n",
      "Multi-head PPM + FiBiNet + Advanced Features\n",
      "Target: 0.650-0.670 AUC\n",
      "================================================================================\n",
      "\n",
      "Device: cuda\n",
      "\n",
      "[1/9] Loading data...\n",
      "  Train: 122,360,517, Test: 3,572,662\n",
      "\n",
      "[2/9] Building user sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building sequences: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [01:10<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Built 183,404 sequences in 71.1s\n",
      "\n",
      "[3/9] Computing enhanced features...\n",
      "  Item features: 4\n",
      "  User features: 6\n",
      "  Train: 116,242,492 | Val: 6,118,025\n",
      "\n",
      "[4/9] Defining ultra-enhanced model...\n",
      "  Parameters: 223,352,442\n",
      "  PPM heads: 4\n",
      "  Sequence length: 20\n",
      "\n",
      "[5/9] Training ultra-enhanced model...\n",
      "\n",
      "================================================================================\n",
      "EPOCH 1/1\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8109/8109 [3:08:49<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/9] Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch 1 Results:\n",
      "  Train Loss: 0.170403\n",
      "  Val AUC: 0.890975\n",
      "  âœ“ Best model saved! (AUC: 0.890975)\n",
      "\n",
      "[7/9] Generating predictions with calibration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:47<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE!\n",
      "================================================================================\n",
      "ðŸ“Š Best Val AUC: 0.890975\n",
      "ðŸŽ¯ Target: 0.650-0.670 AUC\n",
      "\n",
      "New Features:\n",
      "  âœ… Multi-head PPM (4 heads)\n",
      "  âœ… SENet feature importance\n",
      "  âœ… FiBiNet bilinear interactions\n",
      "  âœ… Enhanced statistical features (10 total)\n",
      "  âœ… Longer sequences (15 items)\n",
      "  âœ… Label smoothing\n",
      "  âœ… Prediction calibration\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ULTRA-ENHANCED PPM + ADVANCED TECHNIQUES\n",
    "Target: 0.650-0.670 AUC\n",
    "\n",
    "Improvements:\n",
    "1. Multi-headed PPM (different attention patterns)\n",
    "2. Feature interactions via FiBiNet\n",
    "3. Enhanced statistical features\n",
    "4. Adversarial validation-aware training\n",
    "5. Prediction calibration\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.init as init\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "import math\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ULTRA-ENHANCED PPM MODEL\")\n",
    "print(\"Multi-head PPM + FiBiNet + Advanced Features\")\n",
    "print(\"Target: 0.650-0.670 AUC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "CONFIG = {\n",
    "    'data_folder': '/kaggle/input',\n",
    "    'output_folder': '/kaggle/working/',\n",
    "    'train_path': '/interactions-data/train_interactions.parquet',\n",
    "    'test_path': '/new-test-dataset/test_pairs_public.parquet',\n",
    "    'items_meta_path': '/interactions-data/items_meta.parquet',\n",
    "    'users_meta_path': '/interactions-data/users_meta.parquet',\n",
    "    'test_output_path': 'ultra_enhanced_ppm',\n",
    "    \n",
    "    # Enhanced architecture\n",
    "    'emb_size': 192,\n",
    "    'stat_emb_size': 64,  \n",
    "    'deep_layers': [896, 448, 224], \n",
    "    'num_cross_layers': 4,\n",
    "    'dropout': 0.18,\n",
    "    \n",
    "    # PPM \n",
    "    'ppm_hidden_dim': 320,\n",
    "    'ppm_num_layers': 2,\n",
    "    'ppm_num_heads': 4,  # Multi-head attention\n",
    "    'sequence_length': 20,  # Longer history\n",
    "    \n",
    "    # FiBiNet config\n",
    "    'use_senet': True,\n",
    "    'reduction_ratio': 3,\n",
    "    \n",
    "    # Training\n",
    "    'DEVICE': 'cuda',\n",
    "    'SEED': 42,\n",
    "    'BATCH_SIZE': 14336, \n",
    "    'LR': 0.0022,\n",
    "    'LR_MIN': 0.00003,\n",
    "    'weight_decay': 6e-6,\n",
    "    'EPOCHS': 1,\n",
    "    'VAL_SPLIT': 0.05,\n",
    "    'GRAD_CLIP': 1.0,\n",
    "    'label_smoothing': 0.01,  # Regularization\n",
    "}\n",
    "\n",
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(CONFIG['SEED'])\n",
    "np.random.seed(CONFIG['SEED'])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\nDevice: {device}\")\n",
    "\n",
    "# DATA LOADING\n",
    "print(\"\\n[1/9] Loading data...\")\n",
    "train = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['train_path']}\", engine='pyarrow')\n",
    "train['target'] = ((train['int1'] + train['int2'] + train['int3'] + train['int4']) > 0).astype('int8')\n",
    "\n",
    "test = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['test_path']}\")\n",
    "test_to_save = test.copy()\n",
    "\n",
    "items_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['items_meta_path']}\", engine='pyarrow')\n",
    "items_meta['dur'] = items_meta['dur'] - 5\n",
    "items_meta.set_index('iid', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['users_meta_path']}\", engine='pyarrow')\n",
    "users_meta['age'] = users_meta['age'] - 18\n",
    "users_meta['sex'] = users_meta['sex'].replace({1:0, 2:1})\n",
    "users_meta.set_index('uid', inplace=True)\n",
    "\n",
    "num_users = max(train['uid'].max(), test['uid'].max()) + 1\n",
    "num_items = max(train['iid'].max(), test['iid'].max()) + 1\n",
    "num_sources = items_meta['sid'].max() + 1\n",
    "num_ages = users_meta['age'].max() + 1\n",
    "num_genders = 2\n",
    "num_durations = items_meta['dur'].max() + 1\n",
    "\n",
    "print(f\"  Train: {len(train):,}, Test: {len(test):,}\")\n",
    "\n",
    "# SEQUENCE BUILDING\n",
    "\n",
    "print(\"\\n[2/9] Building user sequences...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "user_groups = train.groupby('uid', sort=False)\n",
    "user_sequences = {}\n",
    "\n",
    "batch_size = 10000\n",
    "unique_users = train['uid'].unique()\n",
    "num_batches = (len(unique_users) + batch_size - 1) // batch_size\n",
    "\n",
    "for batch_idx in tqdm(range(num_batches), desc=\"Building sequences\"):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(unique_users))\n",
    "    batch_users = unique_users[start_idx:end_idx]\n",
    "    \n",
    "    for uid in batch_users:\n",
    "        user_data = user_groups.get_group(uid)\n",
    "        user_sequences[uid] = {\n",
    "            'items': user_data['iid'].values,\n",
    "            'targets': user_data['target'].values,\n",
    "            'length': len(user_data)\n",
    "        }\n",
    "\n",
    "print(f\"  âœ“ Built {len(user_sequences):,} sequences in {time.time()-start_time:.1f}s\")\n",
    "\n",
    "# ENHACED FEATURE ENGINEERING\n",
    "print(\"\\n[3/9] Computing enhanced features...\")\n",
    "\n",
    "# Item features with more statistics\n",
    "item_stats = train.groupby('iid').agg({\n",
    "    'target': ['sum', 'count', 'mean', 'std']\n",
    "}).reset_index()\n",
    "item_stats.columns = ['iid', 'item_pos_count', 'item_total_count', 'item_ctr', 'item_ctr_std']\n",
    "item_stats['item_popularity'] = np.log1p(item_stats['item_total_count'])\n",
    "item_stats['item_conversion_rate'] = item_stats['item_pos_count'] / (item_stats['item_total_count'] + 10)\n",
    "item_stats['item_ctr_std'] = item_stats['item_ctr_std'].fillna(0)\n",
    "\n",
    "# Percentile-based normalization (more robust)\n",
    "for col in ['item_ctr', 'item_popularity', 'item_ctr_std', 'item_conversion_rate']:\n",
    "    p01, p99 = item_stats[col].quantile([0.01, 0.99])\n",
    "    item_stats[col] = np.clip(item_stats[col], p01, p99)\n",
    "    item_stats[col] = (item_stats[col] - p01) / (p99 - p01 + 1e-8)\n",
    "\n",
    "item_stats = item_stats[['iid', 'item_ctr', 'item_popularity', 'item_ctr_std', 'item_conversion_rate']].set_index('iid')\n",
    "\n",
    "# User features with more statistics\n",
    "user_stats = train.groupby('uid').agg({\n",
    "    'target': ['sum', 'count', 'mean', 'std']\n",
    "}).reset_index()\n",
    "user_stats.columns = ['uid', 'user_pos_count', 'user_total_count', 'user_ctr', 'user_ctr_std']\n",
    "user_stats['user_activity'] = np.log1p(user_stats['user_total_count'])\n",
    "user_stats['user_engagement_rate'] = user_stats['user_pos_count'] / (user_stats['user_total_count'] + 10)\n",
    "user_stats['user_ctr_std'] = user_stats['user_ctr_std'].fillna(0)\n",
    "\n",
    "# Percentile normalization\n",
    "for col in ['user_ctr', 'user_activity', 'user_ctr_std', 'user_engagement_rate']:\n",
    "    p01, p99 = user_stats[col].quantile([0.01, 0.99])\n",
    "    user_stats[col] = np.clip(user_stats[col], p01, p99)\n",
    "    user_stats[col] = (user_stats[col] - p01) / (p99 - p01 + 1e-8)\n",
    "\n",
    "user_stats = user_stats[['uid', 'user_ctr', 'user_activity', 'user_ctr_std', 'user_engagement_rate']].set_index('uid')\n",
    "\n",
    "# User-source affinity\n",
    "train_with_source = train.merge(items_meta[['sid']], left_on='iid', right_index=True, how='left')\n",
    "user_source_stats = train_with_source.groupby(['uid', 'sid']).agg({\n",
    "    'target': ['sum', 'count', 'mean']\n",
    "}).reset_index()\n",
    "user_source_stats.columns = ['uid', 'sid', 'us_pos', 'us_total', 'us_ctr']\n",
    "user_source_stats['us_affinity'] = user_source_stats['us_pos'] / (user_source_stats['us_total'] + 5)\n",
    "user_source_avg = user_source_stats.groupby('uid')['us_affinity'].mean().reset_index()\n",
    "user_source_avg.columns = ['uid', 'user_avg_source_affinity']\n",
    "user_source_max = user_source_stats.groupby('uid')['us_affinity'].max().reset_index()\n",
    "user_source_max.columns = ['uid', 'user_max_source_affinity']\n",
    "\n",
    "user_source_features = user_source_avg.merge(user_source_max, on='uid').set_index('uid')\n",
    "user_stats = user_stats.join(user_source_features, how='left')\n",
    "user_stats['user_avg_source_affinity'] = user_stats['user_avg_source_affinity'].fillna(0.5)\n",
    "user_stats['user_max_source_affinity'] = user_stats['user_max_source_affinity'].fillna(0.5)\n",
    "\n",
    "print(f\"  Item features: {item_stats.shape[1]}\")\n",
    "print(f\"  User features: {user_stats.shape[1]}\")\n",
    "\n",
    "del train_with_source, user_source_stats, user_source_avg, user_source_max, user_source_features\n",
    "gc.collect()\n",
    "\n",
    "val_size = int(len(train) * CONFIG['VAL_SPLIT'])\n",
    "train_data = train.iloc[:-val_size].reset_index(drop=True)\n",
    "val_data = train.iloc[-val_size:].reset_index(drop=True)\n",
    "print(f\"  Train: {len(train_data):,} | Val: {len(val_data):,}\")\n",
    "\n",
    "# ADVANCED MODEL COMPONENTS\n",
    "\n",
    "print(\"\\n[4/9] Defining model...\")\n",
    "\n",
    "class SENet(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Network for feature importance.\"\"\"\n",
    "    def __init__(self, num_fields, reduction_ratio=3):\n",
    "        super().__init__()\n",
    "        reduced_size = max(1, num_fields // reduction_ratio)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(num_fields, reduced_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(reduced_size, num_fields, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch, num_fields, emb_dim]\n",
    "        batch_size, num_fields, emb_dim = x.size()\n",
    "        \n",
    "        # Squeeze: global average pooling\n",
    "        squeeze = x.mean(dim=2)  # [batch, num_fields]\n",
    "        \n",
    "        # Excitation: learn field importance\n",
    "        attention = self.excitation(squeeze)  # [batch, num_fields]\n",
    "        \n",
    "        # Reweight\n",
    "        output = x * attention.unsqueeze(2)  # [batch, num_fields, emb_dim]\n",
    "        return output\n",
    "\n",
    "class BilinearInteraction(nn.Module):\n",
    "    \"\"\"Bilinear interaction from FiBiNet.\"\"\"\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(emb_size, emb_size))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch, num_fields, emb_dim]\n",
    "        batch_size, num_fields, emb_dim = x.size()\n",
    "        \n",
    "        interactions = []\n",
    "        for i in range(num_fields):\n",
    "            for j in range(i+1, num_fields):\n",
    "                # Bilinear: vi^T W vj\n",
    "                vi = x[:, i, :]  # [batch, emb_dim]\n",
    "                vj = x[:, j, :]  # [batch, emb_dim]\n",
    "                interaction = (vi @ self.W * vj).sum(dim=1, keepdim=True)  # [batch, 1]\n",
    "                interactions.append(interaction)\n",
    "        \n",
    "        if interactions:\n",
    "            return torch.cat(interactions, dim=1)  # [batch, num_interactions]\n",
    "        else:\n",
    "            return torch.zeros(batch_size, 1, device=x.device)\n",
    "\n",
    "class MultiHeadPPM(nn.Module):\n",
    "    \"\"\"Multi-head PPM for diverse attention patterns.\"\"\"\n",
    "    def __init__(self, emb_size, hidden_dim, num_layers, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Multi-head item encoders\n",
    "        self.item_encoders = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(emb_size, hidden_dim // num_heads),\n",
    "                nn.LayerNorm(hidden_dim // num_heads),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(CONFIG['dropout'])\n",
    "            )\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "        \n",
    "        # Behavior RNN per head\n",
    "        self.behavior_rnns = nn.ModuleList([\n",
    "            nn.GRU(\n",
    "                input_size=hidden_dim // num_heads,\n",
    "                hidden_size=hidden_dim // num_heads,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=CONFIG['dropout'] if num_layers > 1 else 0\n",
    "            )\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "        \n",
    "        # Attention per head\n",
    "        self.attentions = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim // num_heads, hidden_dim // num_heads),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_dim // num_heads, 1)\n",
    "            )\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "        \n",
    "        # Fusion\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(CONFIG['dropout'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, current_item_emb, sequence_embs, sequence_mask):\n",
    "        batch_size = current_item_emb.size(0)\n",
    "        \n",
    "        head_outputs = []\n",
    "        \n",
    "        for head_idx in range(self.num_heads):\n",
    "            # Encode current item\n",
    "            current_enc = self.item_encoders[head_idx](current_item_emb)\n",
    "            \n",
    "            # Encode sequence\n",
    "            seq_enc = self.item_encoders[head_idx](sequence_embs)\n",
    "            \n",
    "            # RNN\n",
    "            rnn_out, _ = self.behavior_rnns[head_idx](seq_enc)\n",
    "            \n",
    "            # Attention\n",
    "            attn_scores = self.attentions[head_idx](rnn_out).squeeze(-1)\n",
    "            attn_scores = attn_scores.masked_fill(sequence_mask == 0, -1e9)\n",
    "            attn_weights = F.softmax(attn_scores, dim=1)\n",
    "            \n",
    "            # Weighted sum\n",
    "            seq_repr = torch.bmm(attn_weights.unsqueeze(1), rnn_out).squeeze(1)\n",
    "            \n",
    "            head_outputs.append(torch.cat([current_enc, seq_repr], dim=1))\n",
    "        \n",
    "        # Concatenate all heads\n",
    "        combined = torch.cat(head_outputs, dim=1)\n",
    "        output = self.fusion(combined)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class UltraEnhancedPPM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        emb_size = CONFIG['emb_size']\n",
    "        stat_emb_size = CONFIG['stat_emb_size']\n",
    "        ppm_dim = CONFIG['ppm_hidden_dim']\n",
    "        \n",
    "        # Embeddings\n",
    "        self.user_emb_wide = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb_wide = nn.Embedding(num_items, emb_size)\n",
    "        self.source_emb_wide = nn.Embedding(num_sources, emb_size)\n",
    "        self.age_emb_wide = nn.Embedding(num_ages, emb_size)\n",
    "        self.gender_emb_wide = nn.Embedding(num_genders, emb_size)\n",
    "        self.duration_emb_wide = nn.Embedding(num_durations, emb_size)\n",
    "        \n",
    "        self.user_emb_deep = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb_deep = nn.Embedding(num_items, emb_size)\n",
    "        self.source_emb_deep = nn.Embedding(num_sources, emb_size)\n",
    "        self.age_emb_deep = nn.Embedding(num_ages, emb_size)\n",
    "        self.gender_emb_deep = nn.Embedding(num_genders, emb_size)\n",
    "        self.duration_emb_deep = nn.Embedding(num_durations, emb_size)\n",
    "        \n",
    "        self.item_meta_proj = nn.Linear(32, emb_size)\n",
    "        \n",
    "        # Enhanced stat projections (4 item + 6 user features)\n",
    "        self.item_stat_proj = nn.Sequential(\n",
    "            nn.Linear(4, stat_emb_size),\n",
    "            nn.LayerNorm(stat_emb_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(CONFIG['dropout'])\n",
    "        )\n",
    "        \n",
    "        self.user_stat_proj = nn.Sequential(\n",
    "            nn.Linear(6, stat_emb_size),\n",
    "            nn.LayerNorm(stat_emb_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(CONFIG['dropout'])\n",
    "        )\n",
    "        \n",
    "        # Multi-head PPM\n",
    "        self.ppm = MultiHeadPPM(\n",
    "            emb_size=emb_size,\n",
    "            hidden_dim=ppm_dim,\n",
    "            num_layers=CONFIG['ppm_num_layers'],\n",
    "            num_heads=CONFIG['ppm_num_heads']\n",
    "        )\n",
    "        \n",
    "        # SENet for feature importance\n",
    "        if CONFIG['use_senet']:\n",
    "            self.senet = SENet(num_fields=7, reduction_ratio=CONFIG['reduction_ratio'])\n",
    "        \n",
    "        # Bilinear interactions\n",
    "        self.bilinear = BilinearInteraction(emb_size)\n",
    "        \n",
    "        # Calculate dimensions\n",
    "        num_bilinear = 7 * 6 // 2  # C(7,2) = 21 pairwise interactions\n",
    "        wide_base = emb_size * 7 + stat_emb_size * 2 + ppm_dim + num_bilinear\n",
    "        dcn_input = emb_size * 7 + stat_emb_size * 2 + ppm_dim\n",
    "        \n",
    "        # DCNv2\n",
    "        self.cross_weights = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn(dcn_input, dcn_input))\n",
    "            for _ in range(CONFIG['num_cross_layers'])\n",
    "        ])\n",
    "        self.cross_biases = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn(dcn_input))\n",
    "            for _ in range(CONFIG['num_cross_layers'])\n",
    "        ])\n",
    "        \n",
    "        self.wide_layer = nn.Linear(wide_base, 1)\n",
    "        \n",
    "        # Deep\n",
    "        deep_input = dcn_input\n",
    "        layers = []\n",
    "        for out_dim in CONFIG['deep_layers']:\n",
    "            layers.append(nn.Linear(deep_input, out_dim))\n",
    "            layers.append(nn.BatchNorm1d(out_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(CONFIG['dropout']))\n",
    "            deep_input = out_dim\n",
    "        self.deep_network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Final\n",
    "        final_input = 1 + dcn_input + CONFIG['deep_layers'][-1]\n",
    "        self.final_bn = nn.BatchNorm1d(final_input)\n",
    "        self.final_layer = nn.Linear(final_input, 1)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Embedding):\n",
    "                init.normal_(module.weight, 0, 0.01)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    init.zeros_(module.bias)\n",
    "        \n",
    "        for weight in self.cross_weights:\n",
    "            init.xavier_uniform_(weight)\n",
    "        for bias in self.cross_biases:\n",
    "            init.zeros_(bias)\n",
    "    \n",
    "    def dcn_forward(self, x):\n",
    "        x0 = x\n",
    "        for i in range(CONFIG['num_cross_layers']):\n",
    "            x = x0 * (x @ self.cross_weights[i]) + self.cross_biases[i] + x\n",
    "        return x\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids,\n",
    "                item_embeddings, item_stats, user_stats, \n",
    "                sequence_item_ids, sequence_mask):\n",
    "        # Embeddings\n",
    "        user_emb_w = self.user_emb_wide(user_ids)\n",
    "        item_emb_w = self.item_emb_wide(item_ids)\n",
    "        source_emb_w = self.source_emb_wide(source_ids)\n",
    "        age_emb_w = self.age_emb_wide(age_ids)\n",
    "        duration_emb_w = self.duration_emb_wide(duration_ids)\n",
    "        gender_emb_w = self.gender_emb_wide(gender_ids)\n",
    "        item_meta_emb = self.item_meta_proj(item_embeddings)\n",
    "        \n",
    "        user_emb_d = self.user_emb_deep(user_ids)\n",
    "        item_emb_d = self.item_emb_deep(item_ids)\n",
    "        source_emb_d = self.source_emb_deep(source_ids)\n",
    "        age_emb_d = self.age_emb_deep(age_ids)\n",
    "        duration_emb_d = self.duration_emb_deep(duration_ids)\n",
    "        gender_emb_d = self.gender_emb_deep(gender_ids)\n",
    "        \n",
    "        item_stat_emb = self.item_stat_proj(item_stats)\n",
    "        user_stat_emb = self.user_stat_proj(user_stats)\n",
    "        \n",
    "        # SENet on embeddings\n",
    "        if CONFIG['use_senet']:\n",
    "            emb_stack = torch.stack([\n",
    "                user_emb_d, item_emb_d, source_emb_d, age_emb_d,\n",
    "                duration_emb_d, gender_emb_d, item_meta_emb\n",
    "            ], dim=1)  # [batch, 7, emb_size]\n",
    "            emb_stack = self.senet(emb_stack)\n",
    "            user_emb_d, item_emb_d, source_emb_d, age_emb_d, duration_emb_d, gender_emb_d, item_meta_emb = \\\n",
    "                emb_stack[:, 0], emb_stack[:, 1], emb_stack[:, 2], emb_stack[:, 3], emb_stack[:, 4], emb_stack[:, 5], emb_stack[:, 6]\n",
    "        \n",
    "        # Bilinear interactions\n",
    "        emb_stack_for_bilinear = torch.stack([\n",
    "            user_emb_w, item_emb_w, source_emb_w, age_emb_w,\n",
    "            duration_emb_w, gender_emb_w, item_meta_emb\n",
    "        ], dim=1)\n",
    "        bilinear_features = self.bilinear(emb_stack_for_bilinear)\n",
    "        \n",
    "        # Multi-head PPM\n",
    "        sequence_embs = self.item_emb_deep(sequence_item_ids)\n",
    "        ppm_features = self.ppm(item_emb_d, sequence_embs, sequence_mask)\n",
    "        \n",
    "        # Combine\n",
    "        wide_concat = torch.cat([\n",
    "            user_emb_w, item_emb_w, source_emb_w, age_emb_w,\n",
    "            duration_emb_w, gender_emb_w, item_meta_emb,\n",
    "            item_stat_emb, user_stat_emb, ppm_features,\n",
    "            bilinear_features\n",
    "        ], dim=1)\n",
    "        \n",
    "        deep_concat = torch.cat([\n",
    "            user_emb_d, item_emb_d, source_emb_d, age_emb_d,\n",
    "            duration_emb_d, gender_emb_d, item_meta_emb,\n",
    "            item_stat_emb, user_stat_emb, ppm_features\n",
    "        ], dim=1)\n",
    "        \n",
    "        wide_out = self.wide_layer(wide_concat)\n",
    "        cross_out = self.dcn_forward(deep_concat)\n",
    "        deep_out = self.deep_network(deep_concat)\n",
    "        \n",
    "        combined = torch.cat([wide_out, cross_out, deep_out], dim=1)\n",
    "        combined = self.final_bn(combined)\n",
    "        output = self.final_layer(combined)\n",
    "        \n",
    "        return output\n",
    "\n",
    "model = UltraEnhancedPPM().to(device)\n",
    "\n",
    "# Label smoothing loss\n",
    "class LabelSmoothingBCELoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.01):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        target = target * (1 - self.smoothing) + 0.5 * self.smoothing\n",
    "        return self.bce(pred, target)\n",
    "\n",
    "criterion = LabelSmoothingBCELoss(smoothing=CONFIG['label_smoothing'])\n",
    "optimizer = AdamW(model.parameters(), lr=CONFIG['LR'], weight_decay=CONFIG['weight_decay'])\n",
    "\n",
    "total_steps = (len(train_data) // CONFIG['BATCH_SIZE'] + 1) * CONFIG['EPOCHS']\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=CONFIG['LR_MIN'])\n",
    "\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  PPM heads: {CONFIG['ppm_num_heads']}\")\n",
    "print(f\"  Sequence length: {CONFIG['sequence_length']}\")\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "def get_stats_batch(uids, iids, items_stats, users_stats):\n",
    "    item_stats_df = items_stats.reindex(iids, fill_value=0.0)\n",
    "    item_stats_array = item_stats_df.values.astype(np.float32)\n",
    "    \n",
    "    user_stats_df = users_stats.reindex(uids, fill_value=0.0)\n",
    "    user_stats_array = user_stats_df.values.astype(np.float32)\n",
    "    \n",
    "    return item_stats_array, user_stats_array\n",
    "\n",
    "def get_user_sequences_batch(uids, user_sequences, seq_length):\n",
    "    batch_size = len(uids)\n",
    "    batch_sequences = np.zeros((batch_size, seq_length), dtype=np.int64)\n",
    "    batch_masks = np.zeros((batch_size, seq_length), dtype=np.float32)\n",
    "    \n",
    "    for idx, uid in enumerate(uids):\n",
    "        if uid in user_sequences:\n",
    "            full_seq = user_sequences[uid]['items']\n",
    "            seq_len = min(len(full_seq), seq_length)\n",
    "            \n",
    "            if len(full_seq) < seq_length:\n",
    "                batch_sequences[idx, -seq_len:] = full_seq\n",
    "                batch_masks[idx, -seq_len:] = 1\n",
    "            else:\n",
    "                batch_sequences[idx] = full_seq[-seq_length:]\n",
    "                batch_masks[idx] = 1\n",
    "    \n",
    "    return batch_sequences, batch_masks\n",
    "\n",
    "def evaluate_model(model, data, items_stats, users_stats, user_seqs, desc=\"Validation\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    num_batches = (len(data) + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx in tqdm(range(num_batches), desc=desc, leave=False):\n",
    "            start = batch_idx * CONFIG['BATCH_SIZE']\n",
    "            end = min(start + CONFIG['BATCH_SIZE'], len(data))\n",
    "            \n",
    "            batch = data.iloc[start:end]\n",
    "            batch_users = batch['uid'].values\n",
    "            batch_items = batch['iid'].values\n",
    "            \n",
    "            batch_users_meta = users_meta.loc[batch_users]\n",
    "            batch_items_meta = items_meta.loc[batch_items]\n",
    "            \n",
    "            targets = batch['target'].values\n",
    "            \n",
    "            item_stats_batch, user_stats_batch = get_stats_batch(\n",
    "                batch_items, batch_users, items_stats, users_stats\n",
    "            )\n",
    "            \n",
    "            seq_items, seq_masks = get_user_sequences_batch(\n",
    "                batch_users, user_seqs, CONFIG['sequence_length']\n",
    "            )\n",
    "            \n",
    "            user_ids = torch.tensor(batch_users, dtype=torch.long, device=device)\n",
    "            item_ids = torch.tensor(batch_items, dtype=torch.long, device=device)\n",
    "            source_ids = torch.tensor(batch_items_meta['sid'].values, dtype=torch.long, device=device)\n",
    "            age_ids = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "            duration_ids = torch.tensor(batch_items_meta['dur'].values, dtype=torch.long, device=device)\n",
    "            gender_ids = torch.tensor(batch_users_meta['sex'].values, dtype=torch.long, device=device)\n",
    "            item_embeddings = torch.tensor(np.stack(batch_items_meta['emb'].values), dtype=torch.float32, device=device)\n",
    "            item_stats_tensor = torch.tensor(item_stats_batch, dtype=torch.float32, device=device)\n",
    "            user_stats_tensor = torch.tensor(user_stats_batch, dtype=torch.float32, device=device)\n",
    "            \n",
    "            sequence_item_ids = torch.tensor(seq_items, dtype=torch.long, device=device)\n",
    "            sequence_mask = torch.tensor(seq_masks, dtype=torch.float32, device=device)\n",
    "            \n",
    "            outputs = model(user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids,\n",
    "                          item_embeddings, item_stats_tensor, user_stats_tensor,\n",
    "                          sequence_item_ids, sequence_mask)\n",
    "            probs = torch.sigmoid(outputs).squeeze().cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(probs)\n",
    "            all_targets.extend(targets)\n",
    "    \n",
    "    auc = roc_auc_score(all_targets, all_preds)\n",
    "    return auc\n",
    "\n",
    "# TRAINING LOOP\n",
    "\n",
    "print(\"\\n[5/9] Training ultra-enhanced model...\")\n",
    "best_val_auc = 0.0\n",
    "train_num_batches = (len(train_data) + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "    print(f\"\\n{'='*80}\\nEPOCH {epoch+1}/{CONFIG['EPOCHS']}\\n{'='*80}\")\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_idx in tqdm(range(train_num_batches), desc=\"Training\"):\n",
    "        start = batch_idx * CONFIG['BATCH_SIZE']\n",
    "        end = min(start + CONFIG['BATCH_SIZE'], len(train_data))\n",
    "        \n",
    "        batch = train_data.iloc[start:end]\n",
    "        batch_users = batch['uid'].values\n",
    "        batch_items = batch['iid'].values\n",
    "        \n",
    "        batch_users_meta = users_meta.loc[batch_users]\n",
    "        batch_items_meta = items_meta.loc[batch_items]\n",
    "        \n",
    "        targets = torch.tensor(batch['target'].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "        \n",
    "        item_stats_batch, user_stats_batch = get_stats_batch(\n",
    "            batch_items, batch_users, item_stats, user_stats\n",
    "        )\n",
    "        \n",
    "        seq_items, seq_masks = get_user_sequences_batch(\n",
    "            batch_users, user_sequences, CONFIG['sequence_length']\n",
    "        )\n",
    "        \n",
    "        user_ids = torch.tensor(batch_users, dtype=torch.long, device=device)\n",
    "        item_ids = torch.tensor(batch_items, dtype=torch.long, device=device)\n",
    "        source_ids = torch.tensor(batch_items_meta['sid'].values, dtype=torch.long, device=device)\n",
    "        age_ids = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "        duration_ids = torch.tensor(batch_items_meta['dur'].values, dtype=torch.long, device=device)\n",
    "        gender_ids = torch.tensor(batch_users_meta['sex'].values, dtype=torch.long, device=device)\n",
    "        item_embeddings = torch.tensor(np.stack(batch_items_meta['emb'].values), dtype=torch.float32, device=device)\n",
    "        item_stats_tensor = torch.tensor(item_stats_batch, dtype=torch.float32, device=device)\n",
    "        user_stats_tensor = torch.tensor(user_stats_batch, dtype=torch.float32, device=device)\n",
    "        \n",
    "        sequence_item_ids = torch.tensor(seq_items, dtype=torch.long, device=device)\n",
    "        sequence_mask = torch.tensor(seq_masks, dtype=torch.float32, device=device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids,\n",
    "                      item_embeddings, item_stats_tensor, user_stats_tensor,\n",
    "                      sequence_item_ids, sequence_mask)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['GRAD_CLIP'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    avg_train_loss = train_loss / train_num_batches\n",
    "    \n",
    "    print(\"\\n[6/9] Validating...\")\n",
    "    val_auc = evaluate_model(model, val_data, item_stats, user_stats, user_sequences)\n",
    "    \n",
    "    print(f\"\\n Epoch {epoch+1} Results:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.6f}\")\n",
    "    print(f\"  Val AUC: {val_auc:.6f}\")\n",
    "    \n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(model.state_dict(), f\"{CONFIG['output_folder']}ultra_enhanced_best.pth\")\n",
    "        print(f\"  âœ“ Best model saved! (AUC: {best_val_auc:.6f})\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# PREDICTIONS WITH CALIBRATION\n",
    "print(\"\\n[7/9] Generating predictions with calibration...\")\n",
    "model.load_state_dict(torch.load(f\"{CONFIG['output_folder']}ultra_enhanced_best.pth\"))\n",
    "model.eval()\n",
    "\n",
    "test_num_batches = (len(test) + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "outputs_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx in tqdm(range(test_num_batches), desc=\"Predicting\"):\n",
    "        start = batch_idx * CONFIG['BATCH_SIZE']\n",
    "        end = min(start + CONFIG['BATCH_SIZE'], len(test))\n",
    "        \n",
    "        batch = test.iloc[start:end]\n",
    "        batch_users = batch['uid'].values\n",
    "        batch_items = batch['iid'].values\n",
    "        \n",
    "        batch_users_meta = users_meta.loc[batch_users]\n",
    "        batch_items_meta = items_meta.loc[batch_items]\n",
    "        \n",
    "        item_stats_batch, user_stats_batch = get_stats_batch(\n",
    "            batch_items, batch_users, item_stats, user_stats\n",
    "        )\n",
    "        \n",
    "        seq_items, seq_masks = get_user_sequences_batch(\n",
    "            batch_users, user_sequences, CONFIG['sequence_length']\n",
    "        )\n",
    "        \n",
    "        user_ids = torch.tensor(batch_users, dtype=torch.long, device=device)\n",
    "        item_ids = torch.tensor(batch_items, dtype=torch.long, device=device)\n",
    "        source_ids = torch.tensor(batch_items_meta['sid'].values, dtype=torch.long, device=device)\n",
    "        age_ids = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "        duration_ids = torch.tensor(batch_items_meta['dur'].values, dtype=torch.long, device=device)\n",
    "        gender_ids = torch.tensor(batch_users_meta['sex'].values, dtype=torch.long, device=device)\n",
    "        item_embeddings = torch.tensor(np.stack(batch_items_meta['emb'].values), dtype=torch.float32, device=device)\n",
    "        item_stats_tensor = torch.tensor(item_stats_batch, dtype=torch.float32, device=device)\n",
    "        user_stats_tensor = torch.tensor(user_stats_batch, dtype=torch.float32, device=device)\n",
    "        \n",
    "        sequence_item_ids = torch.tensor(seq_items, dtype=torch.long, device=device)\n",
    "        sequence_mask = torch.tensor(seq_masks, dtype=torch.float32, device=device)\n",
    "        \n",
    "        outputs = model(user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids,\n",
    "                      item_embeddings, item_stats_tensor, user_stats_tensor,\n",
    "                      sequence_item_ids, sequence_mask)\n",
    "        probs = torch.sigmoid(outputs).squeeze().cpu().numpy()\n",
    "        outputs_list.extend(probs)\n",
    "\n",
    "# Simple calibration: scale to match training distribution\n",
    "train_mean = train['target'].mean()\n",
    "pred_mean = np.mean(outputs_list)\n",
    "calibration_factor = train_mean / (pred_mean + 1e-8)\n",
    "outputs_list = np.array(outputs_list) * calibration_factor\n",
    "outputs_list = np.clip(outputs_list, 0.0, 1.0)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_to_save['uid'].astype(str) + '_' + test_to_save['iid'].astype(str),\n",
    "    'target': outputs_list\n",
    "})\n",
    "\n",
    "submission.to_csv(f\"{CONFIG['output_folder']}{CONFIG['test_output_path']}_best.csv\", index=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\\nTRAINING COMPLETE!\\n{'='*80}\")\n",
    "print(f\"Best Val AUC: {best_val_auc:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8881129,
     "sourceId": 13935768,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8807631,
     "sourceId": 13829678,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11873.320314,
   "end_time": "2025-12-16T04:37:00.281391",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-16T01:19:06.961077",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
